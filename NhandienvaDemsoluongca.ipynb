{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/byzkario105/BaitapAI/blob/main/NhandienvaDemsoluongca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5BkAHegVIgNR",
        "outputId": "85025a93-2790-4bfd-cf5a-6a3b11e15c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code Đếm số lượng cá\n"
      ],
      "metadata": {
        "id": "11FZjxv6POop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import image\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.image import imread\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, BatchNormalization, Dropout, Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, SGD, Optimizer\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.models import load_model \n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from numpy import asarray, save\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import cv2\n",
        "from detecto import core, utils, visualize\n",
        "import matplotlib.image as img\n",
        "\n",
        "\n",
        "#mention you dataset path\n",
        "dataset = core.Dataset(/content/drive/MyDrive/Colab Notebooks/datafish/image/)\n",
        "#mention you object label here\n",
        "model = core.Model(['fish'])\n",
        "\n",
        "\n",
        "\n",
        "model.fit(dataset, epochs=10, verbose=1)\n",
        "\n",
        "model.save ('fish_model_weights.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "sJKNlNjbBJLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import cvlib as cv\n",
        "from detecto import core \n",
        "from detecto.visualize import show_labeled_image, detect_video          \n",
        "# load model\n",
        "model = core.Model.load('ca_model_weights.pth', ['ca'])\n",
        "\n",
        "# open webcam\n",
        "webcam = cv2.VideoCapture(0)\n",
        "\n",
        "# loop through frames\n",
        "while webcam.isOpened():\n",
        "\n",
        "    # read frame from webcam \n",
        "    status, frame = webcam.read()\n",
        "\n",
        "    # apply pig detection\n",
        "    labels, boxes, scores = model.predict(frame)\n",
        "   \n",
        "    filtr_ind=np.where(scores>0.6)\n",
        "    filtr_scr=scores[filtr_ind]\n",
        "    filtr_boxes=boxes[filtr_ind]\n",
        "    num_list = list(filtr_ind[0])\n",
        "    filtr_labels = []\n",
        "    for i in num_list:\n",
        "        filtr_labels.append(labels[i] + \"#\" + str(i+1))\n",
        "    show_labeled_image(frame, filtr_boxes, filtr_labels)\n",
        "    \n",
        "    # display output\n",
        "    cv2.imshow(\"fish detection\", frame)\n",
        "\n",
        "    # press \"Q\" to stop\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# release resources\n",
        "webcam.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "R1rMCKKkBAkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code nhận diện cá\n"
      ],
      "metadata": {
        "id": "FrkFUYD_Pm2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0. Import\n",
        "import cv2\n",
        "from keras.applications.mobilenet import  MobileNet\n",
        "from keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "# 1. Định nghĩa tham số\n",
        "n_class = 5\n",
        "\n",
        "# 2. Build model\n",
        "def get_model():\n",
        "    # Tạo base model\n",
        "    base_model = MobileNet(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
        "    # Tạo model chính\n",
        "    x = base_model.output\n",
        "    # Add some new Fully connected layers to\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    outs = Dense(n_class, activation='softmax')(x)\n",
        "\n",
        "    # Đóng băng các layer của base_model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model = Model(inputs=base_model.inputs, outputs= outs)\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "model.summary()\n",
        "\n",
        "# 3. Make data\n",
        "data_folder = \"/content/drive/MyDrive/Colab Notebooks/datafish/image/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(preprocessing_function= keras.applications.mobilenet.preprocess_input,rotation_range=0.2,\n",
        "                                   width_shift_range=0.2,   height_shift_range=0.2,shear_range=0.3,zoom_range=0.5,\n",
        "                                   horizontal_flip=True, vertical_flip=True,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(data_folder,\n",
        "                                                    target_size=(224, 224),\n",
        "                                                    batch_size=64,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    subset='training')\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_folder,  # same directory as training data\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')  # set as validation data\n",
        "\n",
        "classes = train_generator.class_indices\n",
        "print(classes)\n",
        "classes = list(classes.keys())\n",
        "\n",
        "# 4. Train model\n",
        "n_epochs = 10\n",
        "batch_size = 64\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint('models/best.hdf5', monitor='val_loss', save_best_only = True, mode='auto')\n",
        "callback_list = [checkpoint]\n",
        "\n",
        "step_train = train_generator.n//batch_size\n",
        "step_val = validation_generator.n//batch_size\n",
        "\n",
        "model.fit_generator(generator=train_generator, steps_per_epoch=step_train,\n",
        "                    validation_data=validation_generator,\n",
        "                    validation_steps=step_val,\n",
        "                    callbacks=callback_list,\n",
        "                    epochs=n_epochs)\n",
        "\n",
        "\n",
        "# 5. Lưu model\n",
        "model.save('models/model.h5')"
      ],
      "metadata": {
        "id": "JOeIOJvkPqex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "models=load_model('models/model.h5')\n",
        "model.save('models/ca_model_weights.hdf5')\n",
        "model.save ('models/ca_model_weights.pth')"
      ],
      "metadata": {
        "id": "OmtnjcCYPwXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"Cabasa\",\"Cachep\",\"Camehoa\",\"Camevinh\",\"Carophi\"]"
      ],
      "metadata": {
        "id": "493rD23EPzLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "img = load_img('/content/cachep14.jpg', \n",
        "               target_size=(224, 224))\n",
        "plt.imshow(img)\n",
        "import numpy as np\n",
        "imgRe = img_to_array(img)\n",
        "imgRe = imgRe.reshape(1,224, 224,3)  \n",
        "imgRe = imgRe.astype('float32')\n",
        "imgRe /= 255\n",
        "y_pred = model.predict(imgRe)\n",
        "print(y_pred)\n",
        "y_classes = [np.argmax(element) for element in y_pred]\n",
        "y_classes\n",
        "print(classes[y_classes[0]])"
      ],
      "metadata": {
        "id": "Aa0Un4psP2AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code realtime nhận diện cá"
      ],
      "metadata": {
        "id": "6RJeg2gGP6Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Javascript, Image\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: red; font-weight: bold;\">' +\n",
        "          'Bấm vào video để dừng</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "metadata": {
        "id": "ftSPEeYhP4HT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes"
      ],
      "metadata": {
        "id": "GiMn_UtIQA0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "from google.colab.output import eval_js\n",
        "from google.colab.patches import cv2_imshow\n",
        "from base64 import b64decode, b64encode\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import cv2\n",
        "from keras.models import  load_model\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Đang lấy hình ảnh...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0 \n",
        "\n",
        "# Load model Nhận diện tiền\n",
        "model_file_path = \"/content/models/ca_model_weights.hdf5\"\n",
        "vggmodel = load_model(model_file_path)\n",
        "\n",
        "classes = [\"Cabasa\",\"Cachep\",\"Camehoa\",\"Camevinh\",\"Carophi\"]\n",
        "\n",
        "while True:\n",
        "    # Đọc ảnh trả về từ JS\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "    # convert JS response to OpenCV Image\n",
        "    frame = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # Resize để đưa vào model\n",
        "    frame_p = cv2.resize(frame, dsize=(224,224))\n",
        "    tensor = np.expand_dims(frame_p, axis=0)\n",
        "\n",
        "    # Feed vào mạng\n",
        "    pred = vggmodel.predict(tensor)\n",
        "    class_id = np.argmax(pred)\n",
        "    class_name = classes[class_id]\n",
        "\n",
        "    # Vẽ lên một ảnh để tẹo nữa overlay\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "   \n",
        "    bbox_array = cv2.putText(bbox_array, \"{}\".format(class_name),\n",
        "                        (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
        "                        (0, 255,0), 2)\n",
        "\n",
        "    bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n",
        "    # convert overlay of bbox into bytes\n",
        "    bbox_bytes = bbox_to_bytes(bbox_array)\n",
        "    # update bbox so next frame gets new overlay\n",
        "    bbox = bbox_bytes"
      ],
      "metadata": {
        "id": "CFUJLzUaQCTr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NhandienvaDemsoluongca.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFNb5ldDra2ZMqXyLf9Zsl",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}